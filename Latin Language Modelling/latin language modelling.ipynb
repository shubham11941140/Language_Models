{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Import Word Tokenizer\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Import Laplace Language Model\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = None\n",
    "lat = None\n",
    "\n",
    "with open('./eng.txt', 'r') as f:\n",
    "    eng = f.read()\n",
    "\n",
    "with open('./lat.txt', 'r') as f:\n",
    "    lat = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = eng.split('\\n')\n",
    "lat = lat.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Approval of the Minutes of the previous sitting .',\n",
       " \"The Minutes of yesterday 's sitting have been distributed . \",\n",
       " 'Are there any comments ? ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation of eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_normalized = []\n",
    "for line in eng:\n",
    "    line = line.lower()\n",
    "    line = re.sub(r'[^\\w\\s]','',line)\n",
    "    line = word_tokenize(line)\n",
    "    eng_normalized.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['approval', 'of', 'the', 'minutes', 'of', 'the', 'previous', 'sitting'],\n",
       " ['the',\n",
       "  'minutes',\n",
       "  'of',\n",
       "  'yesterday',\n",
       "  's',\n",
       "  'sitting',\n",
       "  'have',\n",
       "  'been',\n",
       "  'distributed'],\n",
       " ['are', 'there', 'any', 'comments']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_normalized[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_normalized = [line.split() for line in lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_normalized = lat_normalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_normalized is a list of words\n",
    "# form sentences by splitting by '.'\n",
    "lat_normalized = ' '.join(lat_normalized).split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_normalized = [line.split() for line in lat_normalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Approbatio', 'scrupulorum', 'prioris', 'sedentis'],\n",
       " ['Minuta', 'hesterna', 'sedentis', 'distributa', 'sunt'],\n",
       " ['Esne',\n",
       "  'ulla',\n",
       "  'commenta?',\n",
       "  'Mr',\n",
       "  'Praeses,',\n",
       "  'die',\n",
       "  'Lunae',\n",
       "  'punctum',\n",
       "  'ordinis',\n",
       "  'feci',\n",
       "  'de',\n",
       "  'Praeside',\n",
       "  'Nicole',\n",
       "  'Fontaine',\n",
       "  'commentarias',\n",
       "  'relatas',\n",
       "  'in',\n",
       "  'torculari',\n",
       "  'Britannico',\n",
       "  'de',\n",
       "  'recenti',\n",
       "  'visitatione',\n",
       "  'cum',\n",
       "  'Hera',\n",
       "  'Maiestate',\n",
       "  'Regina',\n",
       "  'Elizabeth',\n",
       "  'II']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_normalized[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_English = Laplace(3)\n",
    "Model_Latin = Laplace(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training Data\n",
    "train_data_English, padded_sents_English = padded_everygram_pipeline(3, eng_normalized)\n",
    "Model_English.fit(train_data_English, padded_sents_English)\n",
    "\n",
    "train_data_Latin, padded_sents_Latin = padded_everygram_pipeline(3, lat_normalized)\n",
    "Model_Latin.fit(train_data_Latin, padded_sents_Latin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = 'Petitions are filed'\n",
    "sent2 = 'Praeses ad omnes aspectus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Probabilities\n",
    "\n",
    "# Normalise Sent1\n",
    "sent1 = sent1.lower()\n",
    "sent1 = re.sub(r'[^\\w\\s]','',sent1)\n",
    "sent1 = word_tokenize(sent1)\n",
    "\n",
    "# Normalise Sent2\n",
    "sent2 = sent2.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['petitions', 'are', 'filed'], ['Praeses', 'ad', 'omnes', 'aspectus'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1, sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = list(pad_both_ends(sent1, n=3))\n",
    "sent2 = list(pad_both_ends(sent2, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<s>', '<s>', 'petitions', 'are', 'filed', '</s>', '</s>'],\n",
       " ['<s>', '<s>', 'Praeses', 'ad', 'omnes', 'aspectus', '</s>', '</s>'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1, sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Probabilities\n",
    "def find_prob(sent, model):\n",
    "    prob = 1\n",
    "    for i in range(len(sent)-2):\n",
    "        prob *= model.score(sent[i+2], [sent[i], sent[i+1]])\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Probability:  4.911300098200164e-16\n",
      "Latin Probability:  5.778686910842287e-17\n",
      "English\n"
     ]
    }
   ],
   "source": [
    "# Classify Sentences\n",
    "\n",
    "# Sentence1\n",
    "prob1 = find_prob(sent1, Model_English)\n",
    "prob2 = find_prob(sent1, Model_Latin)\n",
    "\n",
    "print('English Probability: ', prob1)\n",
    "print('Latin Probability: ', prob2)\n",
    "\n",
    "if prob1 > prob2:\n",
    "    print('English')\n",
    "else:\n",
    "    print('Latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Probability:  4.412654354352257e-19\n",
      "Latin Probability:  1.3322621120097489e-19\n",
      "English\n"
     ]
    }
   ],
   "source": [
    "# Sentence2\n",
    "prob1 = find_prob(sent2, Model_English)\n",
    "prob2 = find_prob(sent2, Model_Latin)\n",
    "\n",
    "print('English Probability: ', prob1)\n",
    "print('Latin Probability: ', prob2)\n",
    "\n",
    "if prob1 > prob2:\n",
    "    print('English')\n",
    "else:\n",
    "    print('Latin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a01861876d126b30cd1b77ced19e532f706bc03e1154ffd933be16f6f668bcc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
