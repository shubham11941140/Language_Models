{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIISdgkdWiP4",
        "outputId": "3f97d3df-8613-4111-f37d-10a57e133053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/webtext.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "import string\n",
        "\n",
        "from nltk.corpus import webtext\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE, KneserNeyInterpolated\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('webtext')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "sp = string.punctuation\n",
        "spacy_nlp = spacy.load('en_core_web_sm')\n",
        "all_stopwords = spacy_nlp.Defaults.stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KDbQ8jbcgCYg"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(webtext.sents(), test_size = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svbndc9XgJY_",
        "outputId": "73f41a69-870e-4632-b310-7392c31b9e89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17969, 7701)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(train), len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ykgWhQQ7gs88"
      },
      "outputs": [],
      "source": [
        "def preprocess(sentences):\n",
        "  punc = r\"\"\"!()-[]{};:'\"\\, <>./?@#$%^&*_~\"\"\"\n",
        "  read = \" \".join(sentences)\n",
        "  for ele in read:\n",
        "      if ele in punc:\n",
        "          read = read.replace(ele, \" \") \n",
        "  read = read.lower()\n",
        "\n",
        "  # This will convert the word into tokens\n",
        "  text_tokens = word_tokenize(read)\n",
        "\n",
        "  # Remove all the stopwords from the tokens\n",
        "  tokens_without_sw = [\n",
        "        word for word in text_tokens if not word in stopwords.words(\"english\")\n",
        "    ]\n",
        "  # Initialize the stemmer\n",
        "  ps = PorterStemmer()\n",
        "\n",
        "  # Stem all the words\n",
        "  tokens_without_sw_stem = [ps.stem(word) for word in tokens_without_sw]  \n",
        "\n",
        "  pre_text = [i for i in tokens_without_sw_stem if not i.isnumeric()]\n",
        "  return pre_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HfdE_Zk0lduV"
      },
      "outputs": [],
      "source": [
        "train_sentences = [preprocess(i) for i in train]\n",
        "test_sentences =  [preprocess(i) for i in test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IIJB-Ms0sRM_"
      },
      "outputs": [],
      "source": [
        "def language_model(n, tokenized_text, test_sentences):\n",
        "    average_perplexity = 0.0\n",
        "    train_data, padded_vocab = padded_everygram_pipeline(n, tokenized_text)\n",
        "    lm_model = MLE(n)\n",
        "    lm_model.fit(train_data, padded_vocab)\n",
        "    print(lm_model.counts)\n",
        "    \n",
        "    test_data, _ = padded_everygram_pipeline(n, test_sentences)\n",
        "\n",
        "    for test in list(test_data):\n",
        "        ngrams = list(test)\n",
        "        p = lm_model.perplexity(ngrams)\n",
        "        if p != float('inf'):\n",
        "          average_perplexity += p\n",
        "\n",
        "    sentence_count = len(test_sentences)\n",
        "    average_perplexity /= sentence_count\n",
        "    return average_perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoijAA2sxcx6",
        "outputId": "c503b706-a409-4f32-d873-c43c99f82cfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<NgramCounter with 2 ngram orders and 299617 ngrams>\n",
            "Average Perplexity for Bigram model Webtext Corpus: 16.18012418991258\n"
          ]
        }
      ],
      "source": [
        "n = 2\n",
        "bigram = language_model(n, train_sentences, test_sentences)\n",
        "print(\"Average Perplexity for Bigram model Webtext Corpus:\", bigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2KcN5_gyszB",
        "outputId": "f28a4ae2-e754-4e5d-b46d-0cea094127ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<NgramCounter with 3 ngram orders and 530286 ngrams>\n",
            "Average Perplexity for Trigram model Webtext Corpus: 2.15000497089262\n"
          ]
        }
      ],
      "source": [
        "n = 3\n",
        "trigram = language_model(n, train_sentences, test_sentences)\n",
        "print(\"Average Perplexity for Trigram model Webtext Corpus:\", trigram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2i_IZXNyuHb",
        "outputId": "0d4168f0-8ba9-4046-c9d6-c264eabc7fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<NgramCounter with 4 ngram orders and 814862 ngrams>\n",
            "Average Perplexity for Quadgram model Webtext Corpus: 0.9840472996107742\n"
          ]
        }
      ],
      "source": [
        "n = 4\n",
        "quadgram = language_model(n, train_sentences, test_sentences)\n",
        "print(\"Average Perplexity for Quadgram model Webtext Corpus:\", quadgram)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}